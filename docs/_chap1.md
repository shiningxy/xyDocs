## 书本内容回顾 第一章

### 什么是人工智能

#### 类人行为：图灵测试方法

**图灵测试**是由艾伦·图灵（Alan Turing）提出的。如果人类提问者在提出一些书面问题后无法分辨书面回答来自人还是来自计算机，那么计算机就能通过测试。目前，为计算机编程使其能够通过严格的应用测试尚有大量工作要做。计算机需要具备下列能力：
* **自然语言处理**（natural language processing），以使用人类语言成功地交流；
* **知识表示**（knowledge representation），以存储它所知道或听到的内容；
* **自动推理**（automated reasoning），以回答问题并得出新的结论；
* **机器学习**（machine learning），以适应新的环境，并检测和推断模式。


其他研究人员还提出了**完全图灵测试**，该测试需要与真实世界中的对象和人进行交互。为了通过完全图灵测试，机器人还需要具备以下能力：
* **计算机视觉**（computer vision）和语音识别功能，以感知世界；
* **机器人学**（robotics），以操纵对象并行动。

#### 类人思考：认知建模方法

我们通过三种方式了解人类的思维：

* **内省**（introspection）：试图在自己进行思维活动时捕获思维；
* **心理实验**（psychological experiment）：观察一个人的行为；
* **大脑成像**（brain imageing）：观察大脑的活动。

一旦我们有了足够精确的心智理论，就有可能把这个理论表达为计算机程序。如果程序的输入 / 输出行为与相应的人类行为相匹配，那就表明程序的某些机制也可能在人类中存在。**认知科学**（cognitive science）这一跨学科领域汇集了人工智能的计算机模型和心理学的实验技术，用以构建精确且可测试的人类心智理论。在人工智能发展的早期，这两种方法经常会混淆。有作者认为，如果算法在某个任务中表现良好，就会是建模人类表现的良好模型，反之亦然。而现代作者将这两种主张分开，这种区分使**人工智能**和**认知科学**都得到了更快的发展。

#### 理性思考：“思维法则”方法

到 1965 年，任何用逻辑符号描 
述的可解问题在原则上都可以用程序求解。人工智能中所谓的**逻辑主义**（logicism）传统希望在此类程序的基础上创建智能系统。

按照常规的理解，逻辑要求关于世界的认知是确定的，而实际上这很难实现。例如，我们对政治或战争规则的了解远不如对国际象棋或算术规则的了解。**概率**（probability）论填补了这一鸿沟，允许我们在掌握不确定信息的情况下进行严格的推理。原则上，它允许我们构建全面的理性思维模型，从原始的感知到对世界运作方式的理解，再到对未来的预测。它无法做到的是形成智能行为。为此，我们还需要关于理性行为的理论，仅靠理性思考是不够的。

#### 理性行为：理性智能体方法

**智能体**（agent）就是某种能够采取行动的东西（agent 来自拉丁语 agere，意为“做”）。当然，所有计算机程序都可以完成一些任务，但我们期望计算机智能体能够完成更多的任务：自主运行、感知环境、长期持续存在、适应变化以及制定和实现目标。**理性智能体**（rational agent）需要为取得最佳结果或在存在不确定性时取得最佳期望结果而采取行动。

简而言之，人工智能专注于研究和构建做正确的事情的智能体，其中正确的事情 
是我们提供给智能体的目标定义。这种通用范式非常普遍，以至于我们可以称之为**标准模型**（standard model）。它不仅适用于人工智能，也适用于其他领域。控制理论中，控制器使代价函数最小化；运筹学中，策略使奖励的总和最大化；统计学中，决策规则使损失函数最小；经济学中，决策者追求效用或某种意义的社会福利最大化。

#### 益机

在我们的真实需求和施加给机器的目标之间达成一致的问题称为**价值对齐问题**（value 
alignment problem），即施加给机器的价值或目标必须与人类的一致。如果我们在实验室或模拟器中开发人工智能系统（就像该领域的大多数历史案例一样），就可以轻松地解决目标指定不正确的问题：重置系统、修复目标然后重试。随着人工智能的发展，越来越强大的智能系统需要部署在真实世界中，这种方法不再可行。部署了错误目标的系统将会导致负面影响，而且，系统越智能，其负面影响就越严重。

### 人工智能的基础

#### 哲学

伊曼努尔·康德（Immanuel Kant）在 1785 年提出了一种基于规则或**义务伦理学**（deontological ethics）的理论。在该理论中，“做正确的事”不是由结果决定的，而是由管理可行行为的普适社会法则所决定的，可行行为包括“不要撒谎”“不要杀人”等。因此，如果期望的好处大于坏处，那么功利主义者可以撒一个善意的谎言，但康德主义者则不能这样做，因为撒谎本质上就是错误的。穆勒承认规则的价值，但将其理解为基于第一性原理对结果进行推理的高效决策程序。许多现代人工智能系统正是采用了这种方法。