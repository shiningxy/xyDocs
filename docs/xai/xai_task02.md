## Task02 ZF-NET

### ZF-NET 论文十问

1. 论文试图解决什么问题

这篇论文采取可视化的方式，对深度神经网络的特征层和分类器采取事后解释的方法，试图解决两个问题：一是为人类研究者搞清楚为什么现在的模型能够有很好的性能。二是搞清楚这些模型如何改进。

2. 这是否是一个新的问题

这篇论文于2014年发表，论文中反卷积的思想，已经于2011年被论文的第一作者提出来了。

3. 这篇论文要验证一个什么科学假设

特征不变性。例如平移缩放等，小的变换对于模型第一层的影响很大，模型顶部特征层的影响较小。并且输出结果受到旋转的影响较大，若是对称图像，则影响较小。
模型整体的深度是很重要的，过小的深度会带来很差的结果。
迁移学习能够使模型在相近类型的数据集上有很好的泛化性。

4. 有哪些相关研究？如何归类？谁是这一课题在领域内值得关注的研究员？

这篇论文在当时属于模型可视化的探索，现在被认为是可解释机器学习的早期研究，属于XAI在图像分类领域的研究。Matthew D. Zeiler

5. 论文中提到的解决方案之关键是什么？

反池化，反激活，反卷积

6. 论文中的实验是如何设计的？

移除网络中的某些层，通过消融实验观察结果误差。改变全连接层的大小对性能影响不大。然而，增加中间卷积层的大小可以在性能上获得有用的增益。但是增加中间卷积层，同时也扩大了完全连接的层会导致过拟合。

7. 用于定量评估的数据集是什么？代码有没有开源？

ImageNet 2012, PASCAL 2012, Caltech-101, Caltech-256

8. 论文中的实验及结果有没有很好地支持需要验证的科学假设？

论文表中的数据以及图例，很好地解释了模型对于不同特征层的关注信息不同。同时也可以支撑模型深度对结果误差的影响很重要这一观点假设。其在Table 6上的结果也表明了，迁移学习得到的预训练模型在相差较远的数据集上结果不好。

9. 这篇论文到底有什么贡献？

用神经网络的事后解释方法，很好地解释了特征层到底在做什么，模型到底在关注什么，分类结果是怎么样得到。

10. 下一步呢？有什么工作可以继续深入？

该篇论文在最后提到，这种方法同样适用到object detection，应该已经有后续工作完成了这一任务。
